Chemception: A Deep Neural Network with Minimal Chemistry Knowledge Matches the Performance of Expert-developed QSAR/QSPR Models
(Chemception：最小限の化学知識を持つディープニューラルネットワークは、専門家が開発したQSAR / QSPRモデルの性能と一致します)

要旨
ここ数年、私たちは、特に音声認識やコンピュータビジョンなど、多くのアプリケーションで深い学習の変革の影響を見てきました。
画像分類のためのGoogleのInception-ResNetディープコンボルーションニューラルネットワーク（CNN）に触発され、分子の2D図面の画像だけを使用して、
化学特性予測のための深いCNNである「Chemception」を開発しました。
我々は、周期性のような基本的な概念や分子記述子や指紋などの高度な特徴など、明示的な化学知識を何ら提供せずにChemceptionを開発する。
次に、Chemceptionが、600〜40,000種類の化合物の控えめなデータベースで訓練されたときに毒性、活性および溶媒和特性を予測するための
汎用ニューラルネットワークアーキテクチャとしてどのように役立つかを示します。 
ECFP指紋で訓練された多層パーセプトロン（MLP）深層ニューラルネットワークと比較すると、
Chemceptionは活性および溶媒和予測においてわずかに優れており、毒性予測ではわずかに劣っています。
専門家が開発したQSAR / QSPRディープ・ラーニング・モデルのパフォーマンスと一致して、深いニューラル・ネットワークを使用して計算化学研究を支援する可能性を実証しました。

序文
ImageNet Large Scale Visual Recognition Challenge（ILSVRC）は、コンピュータビジョンアプリケーション向けのさまざまな画像分類コンピュータアルゴリズムの
年間評価と競争です。
2012年には、Hintonと共同研究者によって深い学習アルゴリズムがこのコミュニティに導入され、深層ニューラルネットワーク（DNN）モデルのAlexNetが
25〜30％のエラー率をはるかに上回る16.4％の5つのエラー率を達成しました、その時に採用された最先端のモデルのために。
それ以来、DNNベースのモデルはコンピュータビジョンで使用されている主要なアルゴリズムとなっており、このコミュニティへの深い学習の入門からおよそ3年後の2015年までに
人間の正確さ（トップ5エラーの5％未満）が達成されました。
最近では、高エネルギー粒子物理学、天体物理学、バイオインフォマティクスなどの他の分野で深い学習が始まっており、
化学分野では、2012年の活動予測にMerck Kaggleチャレンジを獲得したDNNベースのモデルと、2014年に毒性予測のためのNIH Tox21の課題が注目されています。
それ以来、多くの研究グループが、活性、毒性、反応性、溶解性、ADMET、ドッキング、霧化エネルギーおよび他の量子特性を含む幅広い特性を予測するDNNベースのモデルの影響を
実証しました。
DNNベースのモデルは、さまざまな化学分野のサブフィールドで行われた最近のレビューでは、
サポートベクターマシンやランダムフォレストなどの従来の機械学習アルゴリズムに基づいた従来の最先端のモデルと同等またはそれ以上の性能を示します。

過去および現在の計算化学アプリケーションで使用されているものを含む他の機械学習アルゴリズムとは異なり、深い学習は非線形関数の階層的カスケードの使用を区別します。
これにより、表現を学習し、所望の特性を予測するために入力データから必要な特徴（化学の文脈における分子記述子および指紋に概念的に類似する）を抽出することが可能になる。
この表現の学習能力は、コンピュータビジョンの「親」分野において深刻な学習が有意かつ変革的な影響を及ぼすことを可能にした重要な能力である。
深い学習の導入に先立ち、コンピュータビジョンの研究者は、適切な機能を開発するために多大な努力を払った。そのようなエキスパート主導の開発は、
主に独自の内部機能を自動的に開発し、特定のタスクで人間レベルの精度を超えたディープ・ラーニング・モデルに置き換えられました。
現在の状態では、深い学習アルゴリズムは、人工の一般的な知能や強力な "AI"システムではないため、
科学的研究プロセスで人間の創造性や知性を置き換えることはできません。
それでも、コンピュータビジョンを超えたタスク特有のアプリケーションで、深い学習が人間と同じくらいよく、時には優れているパフォーマンスを成功裏に実証したことは否定できない。
たとえば、Deep Neural NetworkをベースにしたプログラムであるAlphaGoは、2016年にGoのトッププレーヤーよりも優れていました。
これは、チェスよりも複雑なゲームです.Google Neural Machine Translationなどのアルゴリズムは、人間の翻訳者ほど効果的です
いくつかの言語、および深いニューラルネットワークは、自己駆動車や個人用補助ソフトウェア（Siri、Cortanaなど）を含む
さまざまな「インテリジェントな」ソフトウェアと製品の開発にとって重要でした。
深い学習アルゴリズムを利用したこれらのインパクトの高い例では、ヒューマン・エキスパート、特にフィーチャー・エンジニアリングの分野にあったものが、
深いニューラル・ネットワークの表現能力を大幅に置き換えてきたという共通のテーマがあります。
このような研究パラダイムは、最近のGoogleの機械インテリジェンス研究とMicrosoft AI研究の最近の研究で示されているように、
近代的な深い学習研究の多くを推進しています。


方法

2.2 データの準備
1188/5000
データ作成はPythonを使用して実行され、OpenBabel、Pybel、RDFなどのオープンソースのケミストグラフィーソフトウェアへのスクリプトバインディングをCinfonyインターフェイス経由で利用していました。
データベースの化学物質はSMILES文字列として保存されます。これは、分子の構造を記述するコンパクトな文字列表現です。
SMILESストリングは、上述のケミインフォマティクスソフトウェアを使用して、対応する2D分子構造にデコードされた。
次に、各分子の2D構造の得られた座標を、図2に示すように、各ピクセルが0.5Åの分解能を有する80×80グリッド上にマッピングした。
得られた80×80アレイは、原子または結合の存在に基づいてグレースケール「カラーコード化」された。
具体的には、グリッド上にマッピングされた原子にはその原子質量単位に基づく数が割り当てられ、グリッド上にマッピングされたボンドには、トレーニングセット内の要素の同一性に対応しないので番号2が割り当てられる。
グリッドの他の部分は空（すなわち、真空）であり、番号0にデフォルト設定されていた。
得られた分子の離散化された画像は、次に、訓練のために深い畳み込みニューラルネットワークに解析された。


2.6 DNN
深いニューラルネットワークの理論は、以前の出版物およびレビューで広範に文書化されている。
この原稿では、このセクションでは、深いニューラルネットワークを理解するために必要な概念レベルの詳細を簡単に紹介します。
深い学習アルゴリズムが基づいている人工ニューラルネットワークは、大規模な複雑なデータセットをモデル化および分析するために使用される機械学習アルゴリズムのクラスです。
ニューラルネットワークの基本単位は「ニューロン」であり、概念的および計算上の便宜のために、
これらのニューロンは、ネットワーク設計が生物学的なニューラルネットワークに触発されているレイヤーに編成されています。
ネットワークの各ニューロンは、受信した入力データを非線形関数に写像することによって出力値に変換する計算を実行します。
さらに、調整可能なパラメータ、各ニューロンの機能の「重み」は、
予測された値の誤差を最小にするモデル、ニューラルネットワークを「訓練する」プロセスとして知られている。
操作上、入力はベクトルとして表され、層内のニューロンの重みは行列に配列される。
次に、この層は行列 - ベクトル乗算を行い、続いて非線形活性化関数を実行する。
この論文で開発したChemceptionニューラルネットワークを含む最新のニューラルネットワークでは、整形された線形活性化関数（ReLU）が使用されています。この特定の関数形式は、深いニューラルネットワークを形成するために多くの層を訓練することができます。


